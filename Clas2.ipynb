{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisión de convocatorias de entrenamiento\n",
    "\n",
    "Se extraen las convocatorias de la tabla general y se seleccionan aquellas etiquetadas como perteneciente a la carrera por symplicity (Majors/Concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from observatorio_laboral.offer import OfferController\n",
    "from observatorio_laboral.offer import Offer\n",
    "from observatorio_laboral.offer import DateRange\n",
    "from random import shuffle\n",
    "\n",
    "keyspace = \"l4_test\"\n",
    "table = \"all_offers\"\n",
    "\n",
    "oc = OfferController(keyspace, table)\n",
    "date_range = DateRange(1, 2013, 12, 2017)\n",
    "source = \"symplicity\"\n",
    "\n",
    "oc.load_offers(source, date_range)\n",
    "print(len(oc.offers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offer.ConnectToDatabase(keyspace, \"career_train\")\n",
    "career_offers = []\n",
    "no_career_offers = []\n",
    "\n",
    "for offer in oc.offers:\n",
    "    careers = [career.strip() for career in offer.features['Majors/Concentrations'].split(\",\")]\n",
    "    if \"ECONOMÍA\" in careers:\n",
    "        if len(careers) <= 40:\n",
    "            career_offers.append(offer)\n",
    "    else:\n",
    "        no_career_offers.append(offer)\n",
    "\n",
    "shuffle(no_career_offers)\n",
    "#no_career_offers = no_career_offers[:2*len(career_offers)]\n",
    "\n",
    "for offer in no_career_offers:\n",
    "    offer.table = \"career_train\"\n",
    "    offer.career = \"NO-ECONOMÍA\"\n",
    "    offer.Insert()\n",
    "    \n",
    "for offer in career_offers:\n",
    "    offer.career = \"ECONOMÍA\"\n",
    "    offer.table = \"career_train\"\n",
    "    offer.Insert()\n",
    "    \n",
    "print(len(career_offers))    \n",
    "print(len(no_career_offers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de carreras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from observatorio_laboral.offer import OfferController\n",
    "from observatorio_laboral.offer import Offer\n",
    "from observatorio_laboral.offer import DateRange\n",
    "from random import shuffle\n",
    "\n",
    "keyspace = \"l4_test\"\n",
    "career = \"ECONOMÍA\"\n",
    "\n",
    "oc_train = OfferController(keyspace, \"career_train\")\n",
    "train_date_range = DateRange(1, 2013, 12, 2017)\n",
    "train_source = \"symplicity\"\n",
    "\n",
    "oc_train.load_offers(train_source, train_date_range, career)\n",
    "positive_offers = oc_train.offers\n",
    "print(positive_offers[0].features['Job Title'])\n",
    "\n",
    "oc_train.offers = []\n",
    "oc_train.load_offers(train_source, train_date_range, \"NO-\" + career)\n",
    "negative_offers = oc_train.offers\n",
    "print(negative_offers[0].features['Job Title'])\n",
    "\n",
    "oc_train.offers = positive_offers + negative_offers\n",
    "shuffle(oc_train.offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positive_offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(negative_offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_fields = [\"Job Title\",\n",
    "                     \"Description\",\n",
    "                     \"Qualifications\"]\n",
    "\n",
    "X = oc_train.get_text(train_text_fields)\n",
    "\n",
    "# Simple text preprocesing\n",
    "punctuations = ['•','/', ')', '-']\n",
    "translator = str.maketrans(\"\".join(punctuations),' '*len(punctuations))\n",
    "\n",
    "proc_data = []\n",
    "for text in X:\n",
    "    text = text.lower()\n",
    "    text = text.translate(translator)\n",
    "    proc_data.append(text)    \n",
    "    \n",
    "X = proc_data\n",
    "y = []\n",
    "for offer in oc_train.offers:\n",
    "    if offer.career == \"ECONOMÍA\":\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "#class 'sklearn.feature_selection.univariate_selection.SelectKBest'>\n",
    "#class 'sklearn.naive_bayes.MultinomialNB'>\n",
    "#done in 111.597s\n",
    "\n",
    "#Best F1 score: 0.822\n",
    "#Metrics :\n",
    "#Accuracy: 0.863\n",
    "#             precision    recall  f1-score   support\n",
    "\n",
    "#          0       0.86      0.99      0.92     18754\n",
    "#          1       0.83      0.16      0.27      3487\n",
    "\n",
    "#avg / total       0.86      0.86      0.82     22241\n",
    "\n",
    "#Best parameters set:\n",
    "#\tvec__binary: True\n",
    "#\tvec__norm: 'l2'\n",
    "#\tvec__stop_words: None\n",
    "#\tvec__use_idf: False\n",
    "#=============================\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer(min_df = 0.01,\n",
    "                            binary = True,\n",
    "                            norm = 'l2',\n",
    "                            use_idf=True,\n",
    "                            ngram_range=(1,2)\n",
    "                           )),\n",
    "    #('fs', SelectKBest(chi2, k=1000)),\n",
    "    ('clf', MultinomialNB())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Metrics :\")            \n",
    "\n",
    "print(\"Accuracy: %0.3f\" %  accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pipeline.steps[0][1].get_feature_names()\n",
    "print(len(vocab))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace = \"l4_test\"\n",
    "oc_pred = OfferController(keyspace, \"all_offers\")\n",
    "pred_date_range = DateRange(7, 2016, 6, 2017)\n",
    "pred_source = \"aptitus\"\n",
    "\n",
    "oc_pred.load_offers(pred_source, pred_date_range)\n",
    "print(len(oc_pred.offers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set()\n",
    "for offer in oc_pred.offers:\n",
    "    for feat in offer.features:\n",
    "        features.add(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text_fields = [\"título\",\n",
    "                    \"descripción\",\n",
    "                    \"requisitos\",\n",
    "                    \"NombreAviso\",\n",
    "                    \"FuncionesResponsabilidades\",                    \n",
    "                    \"Requerimientos\",\n",
    "                   ]\n",
    "\n",
    "X_pred = oc_pred.get_text(pred_text_fields)\n",
    "print(X_pred[0])\n",
    "# Simple text preprocesing\n",
    "punctuations = ['•','/', ')', '-']\n",
    "translator = str.maketrans(\"\".join(punctuations),' '*len(punctuations))\n",
    "\n",
    "proc_data = []\n",
    "for text in X_pred:\n",
    "    text = text.lower()\n",
    "    text = text.translate(translator)\n",
    "    proc_data.append(text)    \n",
    "    \n",
    "X_pred = proc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(oc_pred.offers[i].features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pipeline.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "filtered_offers = []\n",
    "for offer, y in zip(oc_pred.offers, y_preds):\n",
    "    if y == 1:\n",
    "        cnt += 1\n",
    "        filtered_offers.append(offer)\n",
    "        #print(offer)\n",
    "#        print(\"=============================================================================================\")\n",
    "#        print()\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fieldnames = [\"ID\",\"year\", \"month\", \"source\",\"Título\", 'Descripción', 'Requerimientos','Empresa', 'Salario']\n",
    "\n",
    "with open(\"Data_A_Limpiar/Economia/Aptitus-2016-2-2017-1.csv\", \"w\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for offer in filtered_offers:\n",
    "        row = {}\n",
    "        row['ID'] = offer.id\n",
    "        row['year'] = offer.year\n",
    "        row['month'] = offer.month\n",
    "        row['source'] = offer.source\n",
    "        \n",
    "        if \"título\" in offer.features:\n",
    "            row['Título'] = offer.features['título']\n",
    "            \n",
    "        if \"NombreAviso\" in offer.features:\n",
    "            row['Título'] = offer.features['NombreAviso']\n",
    "            \n",
    "        if \"descripción\" in offer.features:\n",
    "            row['Descripción'] = offer.features['descripción']\n",
    "            \n",
    "        if \"FuncionesResponsabilidades\" in offer.features:\n",
    "            row['Descripción'] = offer.features['FuncionesResponsabilidades']\n",
    "            \n",
    "        if \"requerimientos\" in offer.features:\n",
    "            row['Requerimientos'] = offer.features['requerimientos']\n",
    "        if \"Requisitos\" in offer.features:\n",
    "            row['Requerimientos'] = offer.features['Requisitos']\n",
    "            \n",
    "        if \"Empresa\" in offer.features:\n",
    "            row['Empresa'] = offer.features['Empresa']\n",
    "            \n",
    "        if \"empresa\" in offer.features:\n",
    "            row['Empresa'] = offer.features['empresa']\n",
    "\n",
    "            \n",
    "        if \"datos de la empresa\" in offer.features:\n",
    "            row['Empresa'] = offer.features['datos de la empresa']\n",
    "            \n",
    "        if \"business\" in offer.features:\n",
    "            row['Empresa'] = offer.features['business']\n",
    "            \n",
    "        if \"condiciones salariales\" in offer.features:\n",
    "            row['Salario'] = offer.features['condiciones salariales']\n",
    "            \n",
    "            \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "vectorizers = [TfidfVectorizer(max_df=0.5, ngram_range=(1,1)),#, min_df=0.01),\n",
    "              ]\n",
    "\n",
    "feature_selectors = [SelectKBest(chi2, k=1000),\n",
    "                     #SelectFromModel(OneVsRestClassifier(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3, C=10000))), \n",
    "                    ]\n",
    "\n",
    "classifiers = [LinearSVC(class_weight=\"balanced\"),               \n",
    "               MultinomialNB(),\n",
    "               BernoulliNB(),\n",
    "              ]\n",
    "\n",
    "parameters = {\n",
    "    #'vec__max_df' : (0.5, 0.75, 1.0),\n",
    "    #'vec__min_df' : (0.0, 0.05, 0.01),\n",
    "    #'vec__ngram_range' : ((1,1), (1,2)),#(1,3)),\n",
    "    #'vec__vocabulary' : (None, vocab),    \n",
    "    'vec__use_idf' : (False, True),\n",
    "    'vec__norm' : (None, 'l2'),\n",
    "    'vec__binary' : (True, False),    \n",
    "    #'vec__tokenizer' : (None, word_tokenize),\n",
    "    'vec__stop_words' : (None, stopwords.words('spanish')),\n",
    "    #'fs__k' : (1000,),    \n",
    "}\n",
    "\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    vec = ('vec', vectorizer)\n",
    "    for feature_selector in feature_selectors:\n",
    "        fs = ('fs', feature_selector)\n",
    "        for classifier in classifiers:\n",
    "            custom_parameters = {}\n",
    "            clf = ('clf', classifier)\n",
    "            \n",
    "            pipeline = Pipeline([vec, fs, clf])\n",
    "            \n",
    "            # Add to dictionaries without altering them\n",
    "            all_params = {**parameters, **custom_parameters}\n",
    "            \n",
    "            grid_search = GridSearchCV(pipeline, all_params,\n",
    "                                       scoring=\"precision\",                                       \n",
    "                                       n_jobs=-1)            \n",
    "            \n",
    "            \n",
    "            print(\"Pipeline: \")\n",
    "            print(vectorizer.__class__)\n",
    "            print(feature_selector.__class__)\n",
    "            print(classifier.__class__)\n",
    "            \n",
    "            t0 = time()\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            #print(len([vocab[i] for i in grid_search.best_estimator_.steps[1][1].get_support(indices=True)]))\n",
    "            print(\"done in %0.3fs\" % (time() - t0))\n",
    "            print()\n",
    "            \n",
    "            print(\"Best F1 score: %0.3f\" % grid_search.best_score_)\n",
    "                        \n",
    "            y_pred = grid_search.predict(X_test)\n",
    "            print(\"Metrics :\")            \n",
    "            \n",
    "            print(\"Accuracy: %0.3f\" %  accuracy_score(y_test, y_pred))            \n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            print(\"Best parameters set:\")            \n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "            for param_name in sorted(all_params.keys()):\n",
    "                if param_name == \"vec__stop_words\":\n",
    "                    if best_parameters[param_name] == None:\n",
    "                        print(\"\\t%s: None\" % (param_name))\n",
    "                    else:\n",
    "                        print(\"\\t%s: spanish\" % (param_name))\n",
    "                elif param_name == \"vec__vocabulary\":\n",
    "                    if best_parameters[param_name] == None:\n",
    "                        print(\"\\t%s: Default\" % (param_name))\n",
    "                    else:\n",
    "                        print(\"\\t%s: Reviewed\" % (param_name))\n",
    "                else:\n",
    "                    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))            \n",
    "            print(\"================================================================\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "from time import time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer(min_df=70, stop_words=stopwords.words('spanish'), ngram_range=(1,3))),\n",
    "    #('fs', SelectKBest(chi2, k=10)),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Metrics :\")            \n",
    "\n",
    "print(\"Accuracy: %0.3f\" %  accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pipeline.steps[0][1].get_feature_names()\n",
    "print(len(vocab))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace = \"l4_test\"\n",
    "oc_pred = OfferController(keyspace, \"all_offers\")\n",
    "pred_date_range = DateRange(1, 2016, 12, 2017)\n",
    "pred_source = \"bumeran\"\n",
    "\n",
    "oc_pred.load_offers(pred_source, pred_date_range)\n",
    "print(len(oc_pred.offers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text_fields = [\"título\",\n",
    "                    \"descripción\",\n",
    "                    \"requerimientos\",\n",
    "                    \"NombreAviso\",\n",
    "                    \"FuncionesResponsabilidades\",\n",
    "                    \"Requisitos\",\n",
    "                   ]\n",
    "\n",
    "X_pred = oc_pred.get_text(pred_text_fields)\n",
    "# Simple text preprocesing\n",
    "punctuations = ['•','/', ')', '-']\n",
    "translator = str.maketrans(\"\".join(punctuations),' '*len(punctuations))\n",
    "\n",
    "proc_data = []\n",
    "for text in X_pred:\n",
    "    text = text.lower()\n",
    "    text = text.translate(translator)\n",
    "    proc_data.append(text)    \n",
    "    \n",
    "X_pred = proc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pipeline.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "filtered_offers = []\n",
    "for offer, y in zip(oc_pred.offers, y_preds):\n",
    "    if y == 1:\n",
    "        cnt += 1\n",
    "        filtered_offers.append(offer)\n",
    "        #print(offer)\n",
    "#        print(\"=============================================================================================\")\n",
    "#        print()\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set()\n",
    "for offer in oc_pred.offers:\n",
    "    for feat in offer.features:\n",
    "        features.add(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fieldnames = [\"ID\",\"Título\", 'Descripción', 'Requerimientos','Empresa', 'Salario']\n",
    "\n",
    "with open(\"Data_A_Limpiar/Geografia/Bumeran.csv\", \"w\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for offer in filtered_offers:\n",
    "        row = {}\n",
    "        row['ID'] = offer.id\n",
    "        \n",
    "        if \"título\" in offer.features:\n",
    "            row['Título'] = offer.features['título']\n",
    "            \n",
    "        if \"NombreAviso\" in offer.features:\n",
    "            row['Título'] = offer.features['NombreAviso']\n",
    "            \n",
    "        if \"descripción\" in offer.features:\n",
    "            row['Descripción'] = offer.features['descripción']\n",
    "            \n",
    "        if \"FuncionesResponsabilidades\" in offer.features:\n",
    "            row['Descripción'] = offer.features['FuncionesResponsabilidades']\n",
    "            \n",
    "        if \"requerimientos\" in offer.features:\n",
    "            row['Requerimientos'] = offer.features['requerimientos']\n",
    "        if \"Requisitos\" in offer.features:\n",
    "            row['Requerimientos'] = offer.features['Requisitos']\n",
    "            \n",
    "        if \"Empresa\" in offer.features:\n",
    "            row['Empresa'] = offer.features['Empresa']\n",
    "            \n",
    "        if \"empresa\" in offer.features:\n",
    "            row['Empresa'] = offer.features['empresa']\n",
    "\n",
    "            \n",
    "        if \"datos de la empresa\" in offer.features:\n",
    "            row['Empresa'] = offer.features['datos de la empresa']\n",
    "            \n",
    "        if \"business\" in offer.features:\n",
    "            row['Empresa'] = offer.features['business']\n",
    "            \n",
    "        if \"condiciones salariales\" in offer.features:\n",
    "            row['Salario'] = offer.features['condiciones salariales']\n",
    "            \n",
    "            \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasar ofertas limpiadas a tabla de l4_offers\n",
    "\n",
    "import csv\n",
    "ids = []\n",
    "with open(\"Data A Clasificar/Economia.csv\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        id = row[\"id\"]\n",
    "        year = int(row['year'])\n",
    "        month = int(row['month'])\n",
    "        source = \"symplicity\"\n",
    "        mark = row['Aceptado']\n",
    "        if mark == 'A':\n",
    "            ids.append((id,year,month, source))\n",
    "            \n",
    "from cassandra.cluster import Cluster\n",
    "from observatorio_laboral.offer.offer import Offer\n",
    "from observatorio_laboral.offer.offer_controller import OfferController\n",
    "from observatorio_laboral.offer.date_range import DateRange\n",
    "\n",
    "Offer.ConnectToDatabase(\"l4_test\", \"reviewed_offers\")\n",
    "cluster = Cluster()\n",
    "session = cluster.connect()\n",
    "\n",
    "#select_cmd = \"\"\"\n",
    "#            SELECT * FROM symplicity.new_offers;\n",
    "#             \"\"\"\n",
    "#result = session.execute(select_cmd);\n",
    "result = Offer.Query(\"l4_test\", \"all_offers\", \"select_all\", ())\n",
    "\n",
    "for row in result:    \n",
    "    id = row.id\n",
    "    year = row.year\n",
    "    month = row.month\n",
    "    careers = row.careers\n",
    "    features = row.features\n",
    "    source = \"symplicity\"\n",
    "\n",
    "    if (id, year, month, source) in ids:\n",
    "        #offer = Offer(source, year, month, id, features, careers)\n",
    "        row.table = \"reviewed_offers\"\n",
    "        row.Insert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "ids = []\n",
    "with open(\"Data_A_Clasificar/rBumeran2016.csv\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        id = row[\"ID\"]\n",
    "        year = int(row['year'])\n",
    "        month = int(row['month'])\n",
    "        source = \"bumeran\"\n",
    "        mark = row['Aceptado']\n",
    "        if mark == 'A':\n",
    "            ids.append((id,year,month, source))\n",
    "from cassandra.cluster import Cluster\n",
    "from observatorio_laboral.offer.offer import Offer\n",
    "from observatorio_laboral.offer.offer_controller import OfferController\n",
    "from observatorio_laboral.offer.date_range import DateRange\n",
    "\n",
    "Offer.ConnectToDatabase(\"l4_test\", \"all_offers\")\n",
    "cluster = Cluster()\n",
    "session = cluster.connect()\n",
    "select_cmd = \"\"\"\n",
    "            SELECT * FROM l4_test.all_offers;\n",
    "             \"\"\"\n",
    "\n",
    "result = session.execute(select_cmd);\n",
    "#result = Offer.Query(\"l4_test\", \"all_offers\", \"select_all\", ())\n",
    "\n",
    "for row in result:\n",
    "    row = Offer.ByRow(\"l4_test\", \"all_offers\", row)\n",
    "    id = row.id\n",
    "    year = row.year\n",
    "    month = row.month\n",
    "    careers = row.career\n",
    "    features = row.features\n",
    "    source = \"bumeran\"\n",
    "\n",
    "    if (id, year, month, source) in ids:\n",
    "        #offer = Offer(source, year, month, id, features, careers)\n",
    "        row.table = \"reviewed_offers\"\n",
    "        row.Insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_cmd = \"\"\"\n",
    "            SELECT * FROM l4_test.all_offers;\n",
    "             \"\"\"\n",
    "\n",
    "result = session.execute(select_cmd);\n",
    "for x in result:\n",
    "    offer = Offer.ByRow(\"l4_test\", \"all_offers\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x in result:\n",
    "    if i == 4 :\n",
    "        break\n",
    "    i+=1\n",
    "    print(x.career)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "ids = []\n",
    "with open(\"Data_A_Clasificar/rApititus2016.csv\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        id = row[\"ID\"]\n",
    "        year = int(row['year'])\n",
    "        month = int(row['month'])\n",
    "        source = \"aptitus\"\n",
    "        mark = row['Aceptado']\n",
    "        if mark == 'A':\n",
    "            ids.append((id,year,month, source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "from cassandra.cluster import Cluster\n",
    "from observatorio_laboral.offer.offer import Offer\n",
    "from observatorio_laboral.offer.offer_controller import OfferController\n",
    "from observatorio_laboral.offer.date_range import DateRange\n",
    "\n",
    "Offer.ConnectToDatabase(\"l4_test\", \"reviewed_offers\")\n",
    "cluster = Cluster()\n",
    "session = cluster.connect()\n",
    "\n",
    "#select_cmd = \"\"\"\n",
    "#            SELECT * FROM symplicity.new_offers;\n",
    "#             \"\"\"\n",
    "#result = session.execute(select_cmd);\n",
    "result = Offer.Query(\"l4_test\", \"all_offers\", \"select_all\", ())\n",
    "\n",
    "for row in result:    \n",
    "    print(\"asd\")\n",
    "    id = row.id\n",
    "    year = row.year\n",
    "    month = row.month\n",
    "    careers = row.careers\n",
    "    features = row.features\n",
    "    source = \"aptitus\"\n",
    "\n",
    "    if (id, year, month, source) in ids:\n",
    "        print(\"asda\")\n",
    "        #offer = Offer(source, year, month, id, features, careers)\n",
    "        row.table = \"reviewed_offers\"\n",
    "        row.Insert()\n",
    "    else :\n",
    "        print(\"gg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasar ofertas limpiadas a tabla de l4_offers\n",
    "\n",
    "import csv\n",
    "with open(\"Data_A_Clasificar/rApititus2016.csv\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        id = row[\"id\"]\n",
    "        year = int(row['year'])\n",
    "        month = int(row['month'])\n",
    "        source = row['source']\n",
    "        mark = row['Aceptado']\n",
    "        career = \"\"\n",
    "        if mark == 'A':            \n",
    "            params = (source, year, month,career, id)\n",
    "            offer = Offer.Query(\"l4_test\", \"all_offers\", \"select_by_id\", params)\n",
    "            offer.Insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "from time import time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer(min_df=0.05, stop_words=stopwords.words('spanish'))),\n",
    "    #('fs', SelectKBest(chi2, k=1000)),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    #'vec__max_df' : (0.5, 0.75, 1.0),\n",
    "    #'vec__min_df' : (0.0, 0.05, 0.01),\n",
    "    'vec__ngram_range' : ((1,1), (1,2), (1,3)),\n",
    "    #'vec__vocabulary' : (None, vocab),    \n",
    "    'vec__use_idf' : (False, True),\n",
    "    'vec__norm' : (None, 'l2'),\n",
    "    #'vec__binary' : (True, False),        \n",
    "    #'vec__stop_words' : (stopwords.words('spanish'),),    \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters,\n",
    "                           scoring=\"precision\",                                       \n",
    "                           n_jobs=-1)\n",
    "\n",
    "print(\"Pipeline: \")\n",
    "t0 = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "#selected_vocab = [vocab[i] for i in grid_search.best_estimator_.steps[1][1].get_support(indices=True)]\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best precision score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Metrics :\")            \n",
    "\n",
    "print(\"Accuracy: %0.3f\" %  accuracy_score(y_test, y_pred))            \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Best parameters set:\")            \n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    if param_name == \"vec__stop_words\":\n",
    "        if best_parameters[param_name] == None:\n",
    "            print(\"\\t%s: None\" % (param_name))\n",
    "        else:\n",
    "            print(\"\\t%s: spanish\" % (param_name))\n",
    "    elif param_name == \"vec__vocabulary\":\n",
    "        if best_parameters[param_name] == None:\n",
    "            print(\"\\t%s: Default\" % (param_name))\n",
    "        else:\n",
    "            print(\"\\t%s: Reviewed\" % (param_name))\n",
    "    else:\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))            \n",
    "print(\"================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace = \"l4_test\"\n",
    "oc_pred = OfferController(keyspace, \"all_offers\")\n",
    "pred_date_range = DateRange(1, 2016, 12, 2016)\n",
    "pred_source = \"aptitus\"\n",
    "\n",
    "oc_pred.load_offers(pred_source, pred_date_range)\n",
    "print(len(oc_pred.offers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text_fields = [\"título\",\n",
    "                    \"descripción\",\n",
    "                    \"requerimientos\",\n",
    "                    \"NombreAviso\",\n",
    "                    \"FuncionesResponsabilidades\",\n",
    "                    \"Requisitos\",\n",
    "                   ]\n",
    "\n",
    "X_pred = oc_pred.get_text(pred_text_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = grid_search.best_estimator_.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for offer, y in zip(X_pred, y_preds):\n",
    "    if y == 1:\n",
    "        cnt += 1\n",
    "        print(offer)\n",
    "        print(\"=============================================================================================\")\n",
    "        print()\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "vectorizers = [TfidfVectorizer(),\n",
    "              ]\n",
    "\n",
    "feature_selectors = [SelectKBest(chi2, k=1000),\n",
    "                     #SelectFromModel(OneVsRestClassifier(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3, C=10000))), \n",
    "                    ]\n",
    "\n",
    "classifiers = [LinearSVC(class_weight=\"balanced\"),               \n",
    "               MultinomialNB(),\n",
    "               BernoulliNB(),\n",
    "              ]\n",
    "\n",
    "parameters = {\n",
    "    'vec__max_df' : (0.5, 0.75, 1.0),\n",
    "    #'vec__min_df' : (0.0, 0.05, 0.01),\n",
    "    'vec__ngram_range' : ((1,1), (1,2), (1,3)),\n",
    "    #'vec__vocabulary' : (None, vocab),    \n",
    "    'vec__use_idf' : (False, True),\n",
    "    'vec__norm' : (None, 'l2'),\n",
    "    'vec__binary' : (True, False),    \n",
    "    #'vec__tokenizer' : (None, word_tokenize),\n",
    "    'vec__stop_words' : (None, stopwords.words('spanish')),\n",
    "    #'fs__k' : (1000,),    \n",
    "}\n",
    "\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    vec = ('vec', vectorizer)\n",
    "    for feature_selector in feature_selectors:\n",
    "        fs = ('fs', feature_selector)\n",
    "        for classifier in classifiers:\n",
    "            custom_parameters = {}\n",
    "            clf = ('clf', classifier)\n",
    "            \n",
    "            pipeline = Pipeline([vec, fs, clf])\n",
    "            \n",
    "            # Add to dictionaries without altering them\n",
    "            all_params = {**parameters, **custom_parameters}\n",
    "            \n",
    "            grid_search = GridSearchCV(pipeline, all_params,\n",
    "                                       scoring=\"precision\",                                       \n",
    "                                       n_jobs=-1)            \n",
    "            \n",
    "            \n",
    "            print(\"Pipeline: \")\n",
    "            print(vectorizer.__class__)\n",
    "            print(feature_selector.__class__)\n",
    "            print(classifier.__class__)\n",
    "            \n",
    "            t0 = time()\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            #print(len([vocab[i] for i in grid_search.best_estimator_.steps[1][1].get_support(indices=True)]))\n",
    "            print(\"done in %0.3fs\" % (time() - t0))\n",
    "            print()\n",
    "            \n",
    "            print(\"Best F1 score: %0.3f\" % grid_search.best_score_)\n",
    "                        \n",
    "            y_pred = grid_search.predict(X_test)\n",
    "            print(\"Metrics :\")            \n",
    "            \n",
    "            print(\"Accuracy: %0.3f\" %  accuracy_score(y_test, y_pred))            \n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            print(\"Best parameters set:\")            \n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "            for param_name in sorted(all_params.keys()):\n",
    "                if param_name == \"vec__stop_words\":\n",
    "                    if best_parameters[param_name] == None:\n",
    "                        print(\"\\t%s: None\" % (param_name))\n",
    "                    else:\n",
    "                        print(\"\\t%s: spanish\" % (param_name))\n",
    "                elif param_name == \"vec__vocabulary\":\n",
    "                    if best_parameters[param_name] == None:\n",
    "                        print(\"\\t%s: Default\" % (param_name))\n",
    "                    else:\n",
    "                        print(\"\\t%s: Reviewed\" % (param_name))\n",
    "                else:\n",
    "                    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))            \n",
    "            print(\"================================================================\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace = \"l4_test\"\n",
    "oc_pred = OfferController(keyspace, \"all_offers\")\n",
    "pred_date_range = DateRange(1, 2016, 12, 2016)\n",
    "pred_source = \"aptitus\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
