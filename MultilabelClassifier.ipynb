{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80706\n",
      "12653\n",
      "553\n"
     ]
    }
   ],
   "source": [
    "# Get data to work with\n",
    "\n",
    "from observatorio_laboral.offer.offer_controller import OfferController\n",
    "from observatorio_laboral.offer.date_range import DateRange\n",
    "\n",
    "text_fields = []\n",
    "oc = OfferController(text_fields = [\"Job Title\", \"Description\", \"Qualifications\"])\n",
    "date_range = DateRange(1, 2013, 5, 2017)\n",
    "source = \"symplicity\"\n",
    "\n",
    "oc.load_offers(source, date_range)\n",
    "print(len(oc.offers))\n",
    "\n",
    "oc.filter_offers_by_career(\"ECONOMÍA\")\n",
    "print(len(oc.offers))\n",
    "\n",
    "oc.filter_offers_by_field(\"Areas\")\n",
    "print(len(oc.offers))\n",
    "\n",
    "offer_texts = oc.get_text()\n",
    "offer_classes = oc.get_field_labels(\"Areas\", ignore=['MC', 'TE', 'OI', 'EI', 'EM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_texts = [text for text, labels in zip(offer_texts, offer_classes) if labels != []]\n",
    "offer_classes = [labels for labels in offer_classes if labels != []]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling approach\n",
    "X = offer_texts\n",
    "y = offer_classes\n",
    "\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#ros = RandomOverSampler(random_state=42)\n",
    "#X_resampled, y_resampled = ros.fit_sample(X,y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = {}\n",
    "with open(\"lemmatization-es.txt\") as lemma_file:\n",
    "    for line in lemma_file:\n",
    "        line = line.split()\n",
    "        lemmatizer[line[1]] = line[0]\n",
    "        \n",
    "        \n",
    "class CustomTokenizer(object):\n",
    "    def __init__(self, lemmatizer):\n",
    "        self.wnl = lemmatizer\n",
    "        self.tok = TfidfVectorizer().build_tokenizer()\n",
    "        \n",
    "    def __call__(self, doc):\n",
    "        #return [word for word in self.tok(doc)]    \n",
    "        tokens = []\n",
    "        for t in self.tok(doc):\n",
    "            while t in self.wnl:\n",
    "                t = self.wnl[t]                \n",
    "            tokens.append(t)                \n",
    "        return tokens\n",
    "custom_tokenizer = CustomTokenizer(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = offer_texts\n",
    "\n",
    "stop_words = stopwords.words('spanish') + ['parar']\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words, tokenizer=custom_tokenizer, norm=None)\n",
    "vec.fit(X) \n",
    "\n",
    "Xtr = vec.fit_transform(X)\n",
    "features = vec.get_feature_names()\n",
    "\n",
    "y_w = np.array([\",\".join(labels) for labels in offer_classes])\n",
    "dfs = top_feats_by_class(Xtr, y_w, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proyectar</td>\n",
       "      <td>3.003235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gestión</td>\n",
       "      <td>2.357437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>procesar</td>\n",
       "      <td>2.235174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>venta</td>\n",
       "      <td>1.844506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experiencia</td>\n",
       "      <td>1.789305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>público</td>\n",
       "      <td>1.779082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>servicio</td>\n",
       "      <td>1.756130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>área</td>\n",
       "      <td>1.700789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>desarrollar</td>\n",
       "      <td>1.654856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comercial</td>\n",
       "      <td>1.602017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>plan</td>\n",
       "      <td>1.554291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>información</td>\n",
       "      <td>1.462737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>año</td>\n",
       "      <td>1.458630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>conocimiento</td>\n",
       "      <td>1.421666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>comer</td>\n",
       "      <td>1.410779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>proponer</td>\n",
       "      <td>1.406248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>riesgo</td>\n",
       "      <td>1.389966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trabajar</td>\n",
       "      <td>1.374787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apoyar</td>\n",
       "      <td>1.356228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>producto</td>\n",
       "      <td>1.328706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>comprar</td>\n",
       "      <td>1.319375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>análisis</td>\n",
       "      <td>1.318995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>unir</td>\n",
       "      <td>1.303122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>evaluación</td>\n",
       "      <td>1.281344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>empresa</td>\n",
       "      <td>1.250685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature     tfidf\n",
       "0      proyectar  3.003235\n",
       "1        gestión  2.357437\n",
       "2       procesar  2.235174\n",
       "3          venta  1.844506\n",
       "4    experiencia  1.789305\n",
       "5        público  1.779082\n",
       "6       servicio  1.756130\n",
       "7           área  1.700789\n",
       "8    desarrollar  1.654856\n",
       "9      comercial  1.602017\n",
       "10          plan  1.554291\n",
       "11   información  1.462737\n",
       "12           año  1.458630\n",
       "13  conocimiento  1.421666\n",
       "14         comer  1.410779\n",
       "15      proponer  1.406248\n",
       "16        riesgo  1.389966\n",
       "17      trabajar  1.374787\n",
       "18        apoyar  1.356228\n",
       "19      producto  1.328706\n",
       "20       comprar  1.319375\n",
       "21      análisis  1.318995\n",
       "22          unir  1.303122\n",
       "23    evaluación  1.281344\n",
       "24       empresa  1.250685"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['PP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['inversión', 'presupuestar', 'realizar', 'seguimiento'], dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(dfs['FI,PP']['feature'], np.union1d(dfs['PP']['feature'], dfs['FI']['feature']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada 0.538461538462 0.6720430107526881 0.8445945945945946\n",
      "Bernou 0.606837606838 0.6896551724137931 0.8108108108108109\n",
      "SVC  0.350427350427 0.6409090909090909 0.9527027027027027\n",
      "Multi 0.649572649573 0.7251461988304093 0.8378378378378378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def ml_score(y_test, y_pred):    \n",
    "    match_cnt = 0\n",
    "    total_cnt = 0\n",
    "    for yt, yp in zip(y_test, y_pred):        \n",
    "        for i, lt in enumerate(yt):\n",
    "            if lt == 1 or yp[i] == 1:\n",
    "                total_cnt += 1\n",
    "                if lt == yp[i]:\n",
    "                    match_cnt += 1           \n",
    "                \n",
    "    return match_cnt/total_cnt\n",
    "\n",
    "\n",
    "def our_score(y_test, y_pred):\n",
    "    match_cnt = 0\n",
    "    total_cnt = 0\n",
    "    for yt, yp in zip(y_test, y_pred):\n",
    "        for i, lt in enumerate(yt):\n",
    "            if lt == 1:\n",
    "                total_cnt += 1                \n",
    "                if lt == yp[i]:\n",
    "                    match_cnt += 1\n",
    "                    \n",
    "    return match_cnt/total_cnt\n",
    "\n",
    "vocab = set(list(dfs['PP']['feature']))\n",
    "vocab.update(set(list(dfs['FI']['feature'])))\n",
    "#vocab.update(set(list(dfs['FI,PP']['feature'])))\n",
    "#vocab.update(set(feats_by_label['P']))\n",
    "#vocab.update(set(feats_by_label['MC']))\n",
    "\n",
    "#vocab.update(set(feats_by_label['F,P']))\n",
    "#vocab.update(set(feats_by_label['EI']))\n",
    "\n",
    "\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(vocabulary=vocab, norm=None, tokenizer=custom_tokenizer)\n",
    "tfidf_vect.fit(X) \n",
    "\n",
    "clfs = []\n",
    "\n",
    "clfs.append((\"Ada\",OneVsRestClassifier(AdaBoostClassifier(random_state=42))))\n",
    "clfs.append((\"Bernou\", OneVsRestClassifier(BernoulliNB())))\n",
    "clfs.append((\"SVC \", OneVsRestClassifier(SVC())))\n",
    "clfs.append((\"Multi\", OneVsRestClassifier(MultinomialNB())))\n",
    "\n",
    "tf_train = tfidf_vect.transform(x_train)\n",
    "tf_test = tfidf_vect.transform(x_test)\n",
    "for name, clf in clfs:\n",
    "    clf.fit(tf_train, y_train)    \n",
    "    y_pred = clf.predict(tf_test)\n",
    "    print(name, accuracy_score(y_test, y_pred), ml_score(y_test, y_pred), our_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi\n",
      "Classes:  ['FI' 'PP']\n",
      "0 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "1 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "2 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "3 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "4 True:  [1 0]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "5 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.3']\n",
      "6 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "7 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.1']\n",
      "8 True:  [0 1]  Pred:  [0 1] Probs:  ['0.4', '0.8']\n",
      "9 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '0.6']\n",
      "10 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.4']\n",
      "11 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.1']\n",
      "12 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "13 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "14 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "15 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "16 True:  [0 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "17 True:  [0 1]  Pred:  [0 1] Probs:  ['0.3', '0.8']\n",
      "18 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "19 True:  [1 0]  Pred:  [1 0] Probs:  ['0.6', '0.5']\n",
      "20 True:  [1 0]  Pred:  [1 1] Probs:  ['0.9', '1.0']\n",
      "21 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "22 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "23 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "24 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '0.8']\n",
      "25 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "26 True:  [1 0]  Pred:  [1 0] Probs:  ['0.7', '0.3']\n",
      "27 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "28 True:  [1 1]  Pred:  [1 1] Probs:  ['0.8', '1.0']\n",
      "29 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '0.9']\n",
      "30 True:  [0 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "31 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "32 True:  [1 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "33 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.1']\n",
      "34 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "35 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "36 True:  [1 0]  Pred:  [1 1] Probs:  ['0.8', '0.8']\n",
      "37 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.4']\n",
      "38 True:  [0 1]  Pred:  [0 0] Probs:  ['0.4', '0.5']\n",
      "39 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "40 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "41 True:  [0 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "42 True:  [0 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "43 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "44 True:  [1 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "45 True:  [0 1]  Pred:  [1 1] Probs:  ['0.9', '0.8']\n",
      "46 True:  [1 1]  Pred:  [1 1] Probs:  ['0.6', '0.7']\n",
      "47 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "48 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "49 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "50 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "51 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "52 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '0.8']\n",
      "53 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.1']\n",
      "54 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.1']\n",
      "55 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "56 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "57 True:  [1 1]  Pred:  [1 1] Probs:  ['0.9', '1.0']\n",
      "58 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.2']\n",
      "59 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.2']\n",
      "60 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "61 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "62 True:  [1 0]  Pred:  [1 1] Probs:  ['0.9', '1.0']\n",
      "63 True:  [0 1]  Pred:  [0 1] Probs:  ['0.2', '0.9']\n",
      "64 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "65 True:  [1 1]  Pred:  [0 1] Probs:  ['0.1', '0.8']\n",
      "66 True:  [0 1]  Pred:  [0 1] Probs:  ['0.1', '1.0']\n",
      "67 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '0.8']\n",
      "68 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.4']\n",
      "69 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "70 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.1']\n",
      "71 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '0.5']\n",
      "72 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "73 True:  [1 1]  Pred:  [1 1] Probs:  ['0.7', '0.6']\n",
      "74 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "75 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "76 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "77 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "78 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "79 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.1']\n",
      "80 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "81 True:  [1 0]  Pred:  [1 1] Probs:  ['0.9', '0.7']\n",
      "82 True:  [0 1]  Pred:  [1 1] Probs:  ['1.0', '0.6']\n",
      "83 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "84 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "85 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '0.7']\n",
      "86 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "87 True:  [0 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "88 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '0.9']\n",
      "89 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "90 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '0.9']\n",
      "91 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "92 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "93 True:  [0 1]  Pred:  [0 1] Probs:  ['0.2', '1.0']\n",
      "94 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "95 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "96 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "97 True:  [1 0]  Pred:  [0 1] Probs:  ['0.0', '0.8']\n",
      "98 True:  [1 1]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "99 True:  [0 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "100 True:  [0 1]  Pred:  [0 1] Probs:  ['0.2', '0.9']\n",
      "101 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.3']\n",
      "102 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.4']\n",
      "103 True:  [1 1]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "104 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "105 True:  [0 1]  Pred:  [0 1] Probs:  ['0.1', '1.0']\n",
      "106 True:  [1 0]  Pred:  [1 1] Probs:  ['1.0', '1.0']\n",
      "107 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.5']\n",
      "108 True:  [0 1]  Pred:  [0 0] Probs:  ['0.3', '0.4']\n",
      "109 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "110 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n",
      "111 True:  [1 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "112 True:  [0 1]  Pred:  [1 0] Probs:  ['0.6', '0.1']\n",
      "113 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.4']\n",
      "114 True:  [0 1]  Pred:  [0 1] Probs:  ['0.1', '1.0']\n",
      "115 True:  [0 1]  Pred:  [0 1] Probs:  ['0.0', '1.0']\n",
      "116 True:  [1 0]  Pred:  [1 0] Probs:  ['1.0', '0.0']\n"
     ]
    }
   ],
   "source": [
    "print(clfs[3][0])\n",
    "clf = clfs[3][1]\n",
    "pred_prob = [[format(p, '.1f') for p in probs] for probs in clf.predict_proba(tf_test)]\n",
    "\n",
    "print(\"Classes: \", mlb.classes_)\n",
    "# Economía Internacional\n",
    "# Finanzas\n",
    "# Teoría Económica\n",
    "# Organización Industrial\n",
    "# Métodos Cuantitativos/Investigación económica\n",
    "# Proyectos/Planeamiento estratégico\n",
    "# Estudios de mercado\n",
    "\n",
    "for idx, (yt, yp, prob) in enumerate(zip(y_test, y_pred, pred_prob)):\n",
    "    print(idx, \"True: \", yt, \" Pred: \", yp , \"Probs: \", prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empresa</td>\n",
       "      <td>12.332839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>riesgo</td>\n",
       "      <td>7.505815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comprar</td>\n",
       "      <td>6.679334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gestión</td>\n",
       "      <td>4.959803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plan</td>\n",
       "      <td>4.620095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>servicio</td>\n",
       "      <td>4.588598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unir</td>\n",
       "      <td>4.021062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>elaboración</td>\n",
       "      <td>3.798610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>proyectar</td>\n",
       "      <td>3.756942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>manejar</td>\n",
       "      <td>3.646639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>área</td>\n",
       "      <td>3.339731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>conocimiento</td>\n",
       "      <td>3.290142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>experiencia</td>\n",
       "      <td>2.531593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>comercial</td>\n",
       "      <td>2.162723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>control</td>\n",
       "      <td>2.090083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>comer</td>\n",
       "      <td>1.873330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>procesar</td>\n",
       "      <td>1.838062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nivel</td>\n",
       "      <td>1.803995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>año</td>\n",
       "      <td>1.406536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cobranza</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature      tfidf\n",
       "0        empresa  12.332839\n",
       "1         riesgo   7.505815\n",
       "2        comprar   6.679334\n",
       "3        gestión   4.959803\n",
       "4           plan   4.620095\n",
       "5       servicio   4.588598\n",
       "6           unir   4.021062\n",
       "7    elaboración   3.798610\n",
       "8      proyectar   3.756942\n",
       "9        manejar   3.646639\n",
       "10          área   3.339731\n",
       "11  conocimiento   3.290142\n",
       "12   experiencia   2.531593\n",
       "13     comercial   2.162723\n",
       "14       control   2.090083\n",
       "15         comer   1.873330\n",
       "16      procesar   1.838062\n",
       "17         nivel   1.803995\n",
       "18           año   1.406536\n",
       "19      cobranza   0.000000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_in_doc(tf_test, tfidf_vect.get_feature_names(), 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['banco', 'cobranza', 'elaboración', 'manejar', 'mercar', 'reportar'], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(dfs['FI']['feature'], np.union1d(dfs['FI,PP']['feature'], dfs['PP']['feature']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANALISTA DE CONSUMO - BPC El Analista de Consumo explora y analiza a profundidad la información de los clientes (tarjeta de crédito y créditos consumo) para encontrar explicación del nivel de riesgo que tienen, deterioros no esperados y mejoras en las políticas de riesgos.\\n\\nPRINCIPALES FUNCIONES:\\n\\n- Contribuye con la identificación de los segmentos de clientes que no son rentables para el banco y que generan pérdidas importantes. Asimismo, identifica segmentos de clientes donde se puede maximizar el valor. \\n- Monitorea toda la cartera a fin de identificar tendencias, se adelanta a posibles deteriores minimizando las pérdidas.\\t\\t\\n- Revisa permanentemente la evolución de las provisiones y realiza los análisis respectivos que expliquen las variaciones importantes para cada producto.\\t\\t\\t\\t\\t\\n- Analiza permanentemente la calidad de cartera del producto y la relación de ésta con la rentabilidad de los mismos, mediante el seguimiento constante de indicadores que muestren el perfil de riesgo y su estabilidad\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n- Participa en el desarrollo y en el uso adecuado de modelos de score y de ingresos, haciendo seguimiento a su performance\\t\\t\\t\\t\\t\\t\\n- Participa en proyectos que involucren a diversas áreas del Banco relacionados con la mejora de procesos.\\t\\n\\n\\nBENEFICIOS:\\n\\n- Ingreso a Planilla BCP con todos beneficios de ley.\\n- Contrato a plazo indeterminado.\\n- Seguro. - Experiencia mínima de tres meses realizando prácticas en finanzas o riesgos.\\n- Manejo de Excel avanzado (funciones, tablas dinámicas).\\n- Manejo de Visual Basic y SQL a nivel básico.\\n- Conocimientos de MS Office a nivel avanzado.\\n- Conocimientos de inglés a nivel intermedio.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec= tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = vec.fit_transform(X)\n",
    "features = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)\n",
    "\n",
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    #tfidf_means = np.nanmean(np.where(matrix!=0,matrix,np.nan),1)\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n",
    "\n",
    "def top_feats_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = {}\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)          \n",
    "        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs[label] = feats_df        \n",
    "    return dfs\n",
    "\n",
    "def plot_tfidf_classfeats_h(dfs):\n",
    "    ''' Plot the data frames returned by the function plot_tfidf_classfeats(). '''\n",
    "    fig = plt.figure(figsize=(12, 9), facecolor=\"w\")\n",
    "    x = np.arange(len(dfs[0]))\n",
    "    for i, df in enumerate(dfs):\n",
    "        ax = fig.add_subplot(1, len(dfs), i+1)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        ax.get_xaxis().tick_bottom()\n",
    "        ax.get_yaxis().tick_left()\n",
    "        ax.set_xlabel(\"Mean Tf-Idf Score\", labelpad=16, fontsize=14)\n",
    "        ax.set_title(\"label = \" + str(df.label), fontsize=16)\n",
    "        ax.ticklabel_format(axis='x', style='sci', scilimits=(-2,2))\n",
    "        ax.barh(x, df.tfidf, align='center', color='#3F5D7D')\n",
    "        ax.set_yticks(x)\n",
    "        ax.set_ylim([-1, x[-1]+1])\n",
    "        yticks = ax.set_yticklabels(df.feature)\n",
    "        plt.subplots_adjust(bottom=0.09, right=0.97, left=0.15, top=0.95, wspace=0.52)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
