{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisión de convocatorias de entrenamiento\n",
    "\n",
    "Se extraen las convocatorias de la tabla general y se seleccionan aquellas etiquetadas como perteneciente a la carrera por symplicity (Majors/Concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from observatorio_laboral.offer import OfferController\n",
    "from observatorio_laboral.offer import Offer\n",
    "from observatorio_laboral.offer import DateRange\n",
    "from random import shuffle\n",
    "\n",
    "keyspace = \"l4_test\"\n",
    "table = \"all_offers\"\n",
    "\n",
    "oc = OfferController(keyspace, table)\n",
    "date_range = DateRange(1, 2013, 12, 2017)\n",
    "source = \"symplicity\"\n",
    "\n",
    "oc.load_offers(source, date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offer.ConnectToDatabase(keyspace, \"reviewed_offers\")\n",
    "career_offers = []\n",
    "no_career_offers = []\n",
    "\n",
    "for offer in oc.offers:\n",
    "    careers = [career.strip() for career in offer.features['Majors/Concentrations'].split(\",\")]\n",
    "    if \"ECONOMÍA\" in careers:\n",
    "        if len(careers) <= 15:           \n",
    "            career_offers.append(offer)\n",
    "    else:\n",
    "        no_career_offers.append(offer)\n",
    "\n",
    "\n",
    "shuffle(no_career_offers)\n",
    "no_career_offers = no_career_offers[:len(career_offers)]\n",
    "for offer in no_career_offers:\n",
    "    offer.table = \"reviewed_offers\"\n",
    "    offer.Insert()\n",
    "    \n",
    "for offer in career_offers:\n",
    "    offer.career = \"ECONOMÍA\"\n",
    "    offer.table = \"reviewed_offers\"\n",
    "    offer.Insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de carreras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 EXPERTO EN COSTOS (SECT. SERVICIOS) - Zona: SURCO\n",
      "Abogado\n"
     ]
    }
   ],
   "source": [
    "from observatorio_laboral.offer import OfferController\n",
    "from observatorio_laboral.offer import Offer\n",
    "from observatorio_laboral.offer import DateRange\n",
    "from random import shuffle\n",
    "\n",
    "keyspace = \"l4_test\"\n",
    "career = \"ECONOMÍA\"\n",
    "\n",
    "oc_train = OfferController(keyspace, \"reviewed_offers\")\n",
    "train_date_range = DateRange(1, 2013, 12, 2017)\n",
    "train_source = \"symplicity\"\n",
    "\n",
    "oc_train.load_offers(train_source, train_date_range, career)\n",
    "positive_offers = oc_train.offers\n",
    "print(positive_offers[0].features['Job Title'])\n",
    "\n",
    "oc_train.offers = []\n",
    "oc_train.load_offers(train_source, train_date_range, career=\"\")\n",
    "negative_offers = oc_train.offers\n",
    "print(negative_offers[0].features['Job Title'])\n",
    "\n",
    "oc_train.offers = positive_offers + negative_offers\n",
    "shuffle(oc_train.offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_fields = [\"Job Title\",\n",
    "                     \"Description\",\n",
    "                     \"Qualifications\"]\n",
    "\n",
    "X = oc_train.get_text(train_text_fields)\n",
    "y = []\n",
    "for offer in oc_train.offers:\n",
    "    if offer.career == \"ECONOMÍA\":\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: \n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_selection.univariate_selection.SelectKBest'>\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "done in 1278.671s\n",
      "\n",
      "Best F1 score: 0.828\n",
      "Metrics :\n",
      "Accuracy: 0.797\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81      3120\n",
      "          1       0.84      0.72      0.78      3021\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6141\n",
      "\n",
      "Best parameters set:\n",
      "\tvec__binary: False\n",
      "\tvec__max_df: 1.0\n",
      "\tvec__ngram_range: (1, 2)\n",
      "\tvec__norm: None\n",
      "\tvec__stop_words: None\n",
      "\tvec__use_idf: True\n",
      "================================================================\n",
      "\n",
      "Pipeline: \n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'sklearn.feature_selection.univariate_selection.SelectKBest'>\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "vectorizers = [TfidfVectorizer(),\n",
    "              ]\n",
    "\n",
    "feature_selectors = [SelectKBest(chi2, k=1000),\n",
    "                     #SelectFromModel(OneVsRestClassifier(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3, C=10000))), \n",
    "                    ]\n",
    "\n",
    "classifiers = [LinearSVC(class_weight=\"balanced\"),               \n",
    "               MultinomialNB(),\n",
    "               BernoulliNB(),\n",
    "              ]\n",
    "\n",
    "parameters = {\n",
    "    'vec__max_df' : (0.5, 0.75, 1.0),\n",
    "    #'vec__min_df' : (0.0, 0.05, 0.01),\n",
    "    'vec__ngram_range' : ((1,1), (1,2), (1,3)),\n",
    "    #'vec__vocabulary' : (None, vocab),    \n",
    "    'vec__use_idf' : (False, True),\n",
    "    'vec__norm' : (None, 'l2'),\n",
    "    'vec__binary' : (True, False),    \n",
    "    #'vec__tokenizer' : (None, word_tokenize),\n",
    "    'vec__stop_words' : (None, stopwords.words('spanish')),\n",
    "    #'fs__k' : (1000,),    \n",
    "}\n",
    "\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    vec = ('vec', vectorizer)\n",
    "    for feature_selector in feature_selectors:\n",
    "        fs = ('fs', feature_selector)\n",
    "        for classifier in classifiers:\n",
    "            custom_parameters = {}\n",
    "            clf = ('clf', classifier)\n",
    "            \n",
    "            pipeline = Pipeline([vec, fs, clf])\n",
    "            \n",
    "            # Add to dictionaries without altering them\n",
    "            all_params = {**parameters, **custom_parameters}\n",
    "            \n",
    "            grid_search = GridSearchCV(pipeline, all_params,\n",
    "                                       scoring=\"precision\",                                       \n",
    "                                       n_jobs=-1)            \n",
    "            \n",
    "            \n",
    "            print(\"Pipeline: \")\n",
    "            print(vectorizer.__class__)\n",
    "            print(feature_selector.__class__)\n",
    "            print(classifier.__class__)\n",
    "            \n",
    "            t0 = time()\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            #print(len([vocab[i] for i in grid_search.best_estimator_.steps[1][1].get_support(indices=True)]))\n",
    "            print(\"done in %0.3fs\" % (time() - t0))\n",
    "            print()\n",
    "            \n",
    "            print(\"Best F1 score: %0.3f\" % grid_search.best_score_)\n",
    "                        \n",
    "            y_pred = grid_search.predict(X_test)\n",
    "            print(\"Metrics :\")            \n",
    "            \n",
    "            print(\"Accuracy: %0.3f\" %  accuracy_score(y_test, y_pred))            \n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            print(\"Best parameters set:\")            \n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "            for param_name in sorted(all_params.keys()):\n",
    "                if param_name == \"vec__stop_words\":\n",
    "                    if best_parameters[param_name] == None:\n",
    "                        print(\"\\t%s: None\" % (param_name))\n",
    "                    else:\n",
    "                        print(\"\\t%s: spanish\" % (param_name))\n",
    "                elif param_name == \"vec__vocabulary\":\n",
    "                    if best_parameters[param_name] == None:\n",
    "                        print(\"\\t%s: Default\" % (param_name))\n",
    "                    else:\n",
    "                        print(\"\\t%s: Reviewed\" % (param_name))\n",
    "                else:\n",
    "                    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))            \n",
    "            print(\"================================================================\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace = \"l4_test\"\n",
    "oc_pred = OfferController(keyspace, \"all_offers\")\n",
    "pred_date_range = DateRange(1, 2016, 12, 2016)\n",
    "pred_source = \"aptitus\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
